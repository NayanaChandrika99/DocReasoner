# TreeStore Architecture

## System Overview

TreeStore is a specialized hierarchical document database built from scratch in Go. It's designed to store and efficiently query tree-structured documents generated by PageIndex.

**Implementation Status (Week 13):**
- âœ… **Core Engine Complete:** B+Tree, transactions, indexes, specialized stores (87 tests passing)
- ğŸš§ **Production Features In Progress:** WAL, gRPC API, Python client, observability

---

## Core Design Principles

### 1. **No Vector Embeddings**
TreeStore aligns with PageIndex's philosophy that reasoning-based retrieval is superior to similarity search. We store structural relationships, not semantic embeddings.

### 2. **Hierarchical First**
The database is optimized for tree operations (parent/child, ancestors, subtrees) rather than flat key-value access.

### 3. **ACID Compliance**
Support atomic transactions, durability via WAL, and snapshot isolation for concurrent access.

### 4. **Performance Focus**
Sub-10ms query latency for typical document operations through careful indexing and caching.

---

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    TreeStore System (Extended)              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              gRPC API Layer                        â”‚    â”‚
â”‚  â”‚  - Request validation                              â”‚    â”‚
â”‚  â”‚  - Error handling                                  â”‚    â”‚
â”‚  â”‚  - Metrics collection                              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚          Service Layer (Multiple Stores)           â”‚    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚  DocumentService - Policy tree nodes & hierarchy   â”‚    â”‚
â”‚  â”‚  VersionService  - Temporal queries & versioning   â”‚    â”‚
â”‚  â”‚  MetadataService - Tool results & trajectories     â”‚    â”‚
â”‚  â”‚  PromptService   - Prompt versioning               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚           Index Manager (Multiple B+Trees)         â”‚    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚  DocumentStore:                                    â”‚    â”‚
â”‚  â”‚  â”œâ”€ Primary Index  (policy_id, node_id)           â”‚    â”‚
â”‚  â”‚  â”œâ”€ Parent Index   (policy_id, parent_id)         â”‚    â”‚
â”‚  â”‚  â””â”€ Page Index     (policy_id, page_num)          â”‚    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚  VersionStore:                                     â”‚    â”‚
â”‚  â”‚  â””â”€ Temporal Index (policy_id, effective_date)    â”‚    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚  MetadataStore:                                    â”‚    â”‚
â”‚  â”‚  â”œâ”€ Tool Results   (case_id, tool_name)           â”‚    â”‚
â”‚  â”‚  â”œâ”€ Trajectories   (case_id, timestamp)           â”‚    â”‚
â”‚  â”‚  â””â”€ Cross-Refs     (from_node_id, to_node_id)     â”‚    â”‚
â”‚  â”‚                                                     â”‚    â”‚
â”‚  â”‚  PromptStore:                                      â”‚    â”‚
â”‚  â”‚  â””â”€ Prompts        (prompt_id, version)           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚          Transaction Manager (MVCC)                â”‚    â”‚
â”‚  â”‚  - Begin/Commit/Rollback                          â”‚    â”‚
â”‚  â”‚  - Snapshot isolation                             â”‚    â”‚
â”‚  â”‚  - Conflict detection                             â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚             B+Tree Storage Engine                  â”‚    â”‚
â”‚  â”‚  - Insert/Get/Delete/RangeScan                    â”‚    â”‚
â”‚  â”‚  - Node splitting/merging                         â”‚    â”‚
â”‚  â”‚  - Tree rebalancing                               â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Page Manager                          â”‚    â”‚
â”‚  â”‚  - Page allocation/deallocation                   â”‚    â”‚
â”‚  â”‚  - Buffer pool (LRU cache)                        â”‚    â”‚
â”‚  â”‚  - Free list management                           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚         Write-Ahead Log (WAL)                      â”‚    â”‚
â”‚  â”‚  - Sequential log writing                         â”‚    â”‚
â”‚  â”‚  - Crash recovery                                 â”‚    â”‚
â”‚  â”‚  - Checkpointing                                  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                      â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              Disk I/O Layer                        â”‚    â”‚
â”‚  â”‚  - File operations                                â”‚    â”‚
â”‚  â”‚  - Fsync for durability                           â”‚    â”‚
â”‚  â”‚  - OS page cache interaction                      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Component Details

### 1. Storage Engine (B+Tree)

**Purpose:** Core data structure for storing and retrieving key-value pairs

**Design Decisions:**
- **B+Tree over LSM-Tree:** Better for read-heavy workloads and range scans
- **Page Size:** 4KB (matches OS page size for efficiency)
- **Fanout:** ~100-200 keys per node (minimizes tree height)
- **Leaf Node Chaining:** Enables efficient range scans

**Key Operations:**
```go
type BTree interface {
    Insert(key, value []byte) error
    Get(key []byte) ([]byte, error)
    Delete(key []byte) error
    RangeScan(start, end []byte) Iterator
}
```

**Data Layout:**
```
Internal Node:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Header | N | Key1 | Ptr1 | Key2 | Ptr2 â”‚...
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Leaf Node:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Header | N | Key1 | Val1 | Key2 | Val2 â”‚... | NextLeafPtr
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 2. Write-Ahead Log (WAL)

**Purpose:** Ensure durability and enable crash recovery

**Implementation Status:** âŒ NOT IMPLEMENTED (Week 14 in progress)
- `pkg/wal/` directory exists but is empty
- Current system uses copy-on-write for atomicity but lacks crash recovery

**Planned Design:**
```
Log Entry Format:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LSN | TxnID | OpType | Key | Value | Timestamp | CRC32
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

OpType: INSERT, DELETE, COMMIT, CHECKPOINT
LSN: Log Sequence Number (monotonically increasing)
CRC32: Checksum for corruption detection
```

**Write Process (To Be Implemented):**
1. Write operation â†’ Create WAL entry
2. Append to log file with fsync
3. Update in-memory B+Tree
4. Return success

**Recovery Process (To Be Implemented):**
1. On startup, read all log entries after last checkpoint
2. Replay operations into B+Tree
3. Rebuild indexes
4. Resume normal operation

**Log Rotation (To Be Implemented):**
- New log file every 100MB
- Keep last 3 log files for safety
- Background checkpoint process every 10 minutes

**Current Workaround:**
- Copy-on-write provides atomicity for single transactions
- No durability guarantees if process crashes before flush
- Acceptable for development/testing, NOT for production

---

### 3. Index Manager

**Purpose:** Maintain multiple B+Trees for different access patterns

**Indexes:**

#### Primary Index
```
Key:   (policy_id, node_id)
Value: {title, parent_id, page_start, page_end, summary, text, ...}
```

#### Parent Index
```
Key:   (policy_id, parent_id, child_node_id)
Value: node_id
Purpose: Fast GetChildren() queries
```

#### Page Index
```
Key:   (policy_id, page_num, node_id)
Value: node_id
Purpose: Find nodes by page number
```

#### Path Index
```
Key:   (policy_id, path_hash)
Value: node_id
Purpose: Fast path-based lookups
```

**Consistency:**
All indexes updated atomically within transaction

---

### 4. Transaction Manager (MVCC)

**Purpose:** Provide snapshot isolation for concurrent transactions

**Design:**
- **Timestamp Ordering:** Each transaction gets monotonic timestamp
- **Version Chains:** Multiple versions of same key
- **Garbage Collection:** Remove old versions when no longer needed

**Transaction Lifecycle:**
```go
txn := db.BeginTransaction()
defer txn.Rollback()  // Cleanup if not committed

// Reads see snapshot at txn start time
value := txn.Get(key)

// Writes are buffered
txn.Put(key, newValue)

// Atomic commit
txn.Commit()
```

**Isolation Levels:**
- Default: Snapshot Isolation (SI)
- Optional: Serializable (detect write-write conflicts)

---

### 5. Service Layer (Extended with Multiple Stores)

TreeStore now consists of **four specialized stores** that share the same underlying B+Tree infrastructure:

#### A. DocumentStore - Policy Tree Nodes

**Purpose:** Store and query hierarchical policy documents from PageIndex

**Data Model:**
```go
type Document struct {
    PolicyID       string
    VersionID      string
    PageIndexDocID string
    RootNodeID     string
    NodeCount      int
    EffectiveDate  *time.Time  // NEW: For temporal queries
    RevisionDate   *time.Time  // NEW
    CreatedAt      time.Time
    Metadata       DocumentMetadata  // NEW
}

type DocumentMetadata struct {
    ProcessedBy    string
    PageCount      int
    ToolsUsed      []string
}

type Node struct {
    NodeID       string
    ParentID     *string
    Title        string
    PageStart    int
    PageEnd      int
    Summary      string
    Text         string
    SectionPath  string
    ChildIDs     []string
    
    // NEW: Cross-references
    SeeAlso      []string  // Related node IDs
    ReferencedBy []string  // Nodes referencing this
    
    // NEW: Metadata
    LastUpdated  time.Time
    Confidence   float64   // From PageIndex processing
}
```

#### B. VersionStore - Temporal Queries

**Purpose:** Support `temporal_lookup` tool - get policy version as of specific date

**Data Model:**
```go
type PolicyVersion struct {
    PolicyID      string
    VersionID     string
    EffectiveDate time.Time
    EndDate       *time.Time  // When this version was superseded
    Changes       []VersionDiff
    CreatedAt     time.Time
}

type VersionDiff struct {
    NodeID    string
    ChangeType string  // "added", "modified", "deleted"
    OldValue  string
    NewValue  string
}
```

**Key Operations:**
```go
// Get version effective on a specific date
func (vs *VersionStore) GetVersionAsOf(
    policyID string,
    asOfDate time.Time,
) (*PolicyVersion, error)

// List all versions for a policy
func (vs *VersionStore) ListVersions(
    policyID string,
) ([]*PolicyVersion, error)
```

#### C. MetadataStore - Tool Results & Trajectories

**Purpose:** Store results from ReAct tools (pi_search, facts_get, etc.)

**Data Model:**
```go
// Tool result storage
type ToolResult struct {
    CaseID      string
    CriterionID string
    ToolName    string  // "pi_search", "facts_get", etc.
    Input       map[string]interface{}
    Output      map[string]interface{}
    Timestamp   time.Time
    Latency     time.Duration
    Success     bool
}

// Search trajectory storage (from pi_search)
type SearchTrajectory struct {
    CaseID       string
    Query        string
    NodesVisited []string
    Thinking     string
    Confidence   float64
    Method       string  // "llm", "hybrid", "mcts"
    Timestamp    time.Time
}

// Cross-reference storage (for policy_xref tool)
type CrossReference struct {
    FromNodeID   string
    ToNodeID     string
    RelationType string  // "see_also", "prerequisite", "related"
    Reason       string
    Confidence   float64
}

// Contradiction storage (from contradiction_detector tool)
type Contradiction struct {
    CaseID       string
    CriterionID  string
    Evidence     []EvidencePiece
    Conflicts    []Conflict
    Resolution   string
    Timestamp    time.Time
}

type EvidencePiece struct {
    NodeID   string
    Snippet  string
    Stance   string  // "support", "oppose", "neutral"
}
```

**Key Operations:**
```go
// Store tool result
func (ms *MetadataStore) StoreToolResult(
    result *ToolResult,
) error

// Store search trajectory
func (ms *MetadataStore) StoreTrajectory(
    trajectory *SearchTrajectory,
) error

// Get cross-references for policy_xref tool
func (ms *MetadataStore) GetCrossReferences(
    nodeID string,
) ([]*CrossReference, error)

// Store contradiction for analysis
func (ms *MetadataStore) StoreContradiction(
    contradiction *Contradiction,
) error
```

#### D. PromptStore - Versioned Prompts

**Purpose:** Track which system prompts were used for decisions

**Data Model:**
```go
type Prompt struct {
    PromptID    string
    Version     string
    Content     string
    ToolSchemas []ToolSchema
    CreatedAt   time.Time
    DeployedAt  *time.Time
    RetiredAt   *time.Time
}

type ToolSchema struct {
    Name        string
    Description string
    Parameters  map[string]interface{}
}

type PromptUsage struct {
    CaseID      string
    PromptID    string
    Version     string
    Timestamp   time.Time
}
```

**Key Operations:**
```go
// Store new prompt version
func (ps *PromptStore) StorePrompt(
    prompt *Prompt,
) error

// Get prompt by version
func (ps *PromptStore) GetPrompt(
    promptID string,
    version string,
) (*Prompt, error)

// Track which prompt was used
func (ps *PromptStore) RecordUsage(
    usage *PromptUsage,
) error
```

**Key Operations:**

#### StoreDocument
```go
func (ds *DocumentService) StoreDocument(
    policyID string,
    tree map[string]interface{},
) error {
    txn := ds.db.BeginTransaction()
    defer txn.Rollback()
    
    // Parse tree structure
    nodes := flattenTree(tree)
    
    // Store document metadata
    doc := Document{...}
    txn.Put(docKey, serialize(doc))
    
    // Batch insert all nodes
    for _, node := range nodes {
        // Primary index
        txn.Put(primaryKey(node), serialize(node))
        
        // Secondary indexes
        txn.Put(parentKey(node), node.NodeID)
        txn.Put(pageKey(node), node.NodeID)
    }
    
    return txn.Commit()
}
```

#### GetSubtree
```go
func (ds *DocumentService) GetSubtree(
    policyID string,
    nodeID string,
    maxDepth int,
) (*Node, error) {
    // BFS traversal with depth limit
    root := ds.GetNode(policyID, nodeID)
    queue := [](*Node, int){{root, 0}}
    
    for len(queue) > 0 {
        node, depth := queue[0]
        queue = queue[1:]
        
        if depth < maxDepth {
            children := ds.GetChildren(policyID, node.NodeID)
            node.Children = children
            
            for _, child := range children {
                queue = append(queue, (child, depth+1))
            }
        }
    }
    
    return root, nil
}
```

---

### 6. Full-Text Search

**Purpose:** Keyword search over titles and summaries (NOT semantic)

**Design:**
- **Inverted Index:** word â†’ list of (document, node_id, positions)
- **BM25 Ranking:** Rank results by keyword relevance
- **Stop Words:** Filter common words

**Index Structure:**
```
Word: "eligibility"
Postings: [
    (policy_123, node_0042, [5, 23, 47]),
    (policy_123, node_0043, [12]),
    (policy_456, node_0015, [8, 91])
]
```

**Query Processing:**
1. Tokenize query
2. Lookup each term in inverted index
3. Intersect/union posting lists
4. Score with BM25
5. Return top-K results

---

## Data Flow Examples

### Example 1: Storing PageIndex Output

```
1. Python Client
   â†“
   grpc.StoreDocument(policy_id="POL123", tree_json={...})
   
2. gRPC Server
   â†“
   DocumentService.StoreDocument()
   
3. Document Service
   â†“
   - Flatten tree into nodes
   - Begin transaction
   - For each node:
     * Insert into primary index
     * Update parent index
     * Update page index
     * Update full-text index
   - Commit transaction
   
4. Transaction Manager
   â†“
   - Assign transaction ID
   - Write to WAL
   - Update B+Trees
   - Fsync
   - Return success
```

### Example 2: Tree Traversal Query

```
1. Python Client
   â†“
   grpc.GetSubtree(policy_id="POL123", node_id="0042", max_depth=2)
   
2. gRPC Server
   â†“
   DocumentService.GetSubtree()
   
3. Document Service
   â†“
   - Get root node from primary index
   - BFS traversal:
     * For each node at depth < max_depth:
       - Query parent index for children
       - Fetch child nodes from primary index
   - Assemble tree structure
   - Return result
   
4. B+Tree Storage
   â†“
   - Lookup in primary index: O(log N)
   - Range scan in parent index: O(log N + M) where M = num children
   - Total: O(nodes_in_subtree * log N)
```

---

## Performance Characteristics

### Time Complexity

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| **DocumentStore** | | |
| Get Node | O(log N) | Single B+Tree lookup |
| Get Children | O(log N + M) | Range scan, M = num children |
| Get Subtree | O(K log N) | K = nodes in subtree |
| Insert Node | O(log N * I) | I = num indexes |
| Range Scan | O(log N + M) | M = num results |
| Keyword Search | O(T + R log R) | T = term lookups, R = results |
| **VersionStore** | | |
| Get Version As Of | O(log N) | Range scan on temporal index |
| List Versions | O(log N + V) | V = num versions |
| **MetadataStore** | | |
| Store Tool Result | O(log N) | Single insert |
| Store Trajectory | O(log N) | Single insert |
| Get Cross-Refs | O(log N + R) | R = num references |
| **PromptStore** | | |
| Store Prompt | O(log N) | Single insert |
| Get Prompt | O(log N) | Single lookup |
| **Overall** | | |
| End-to-End Tool Call | O(log N) | Typically <20ms |

### Space Complexity

| Component | Size | Notes |
|-----------|------|-------|
| **DocumentStore** | | |
| B+Tree Node | 4KB | 1 page |
| Policy Node | ~1KB | With indexes |
| Secondary Indexes | ~100 bytes/node | Per index |
| **VersionStore** | | |
| Policy Version | ~500 bytes | Metadata only |
| Version Diffs | ~200 bytes/diff | Small changes |
| **MetadataStore** | | |
| Tool Result | ~500 bytes | Average |
| Search Trajectory | ~1KB | With thinking |
| Cross-Reference | ~100 bytes | Small |
| Contradiction | ~2KB | With evidence |
| **PromptStore** | | |
| Prompt | ~5KB | With schemas |
| Prompt Usage | ~100 bytes | Reference only |
| **WAL** | | |
| WAL Entry | ~500 bytes | Per operation |

**Storage Estimates (Year 1):**
- 50 policies Ã— 200 nodes = 10K nodes Ã— 1.5KB = **15MB** (DocumentStore)
- 1000 cases/day Ã— 10 tools/case Ã— 0.5KB Ã— 365 days = **1.8GB** (MetadataStore)
- 10 prompt versions Ã— 5KB = **50KB** (PromptStore)
- 50 policies Ã— 5 versions Ã— 1KB = **250KB** (VersionStore)

**Total Year 1:** ~2GB (easily cached in memory)

---

## Concurrency Model

### Read-Write Lock Strategy

```
Multiple readers, single writer:
- Readers acquire read lock (shared)
- Writer acquires write lock (exclusive)
- MVCC allows readers to see consistent snapshot
```

### Transaction Isolation

```
Snapshot Isolation (SI):
- Each transaction sees snapshot at start time
- Reads never block writes
- Writes never block reads
- Write-write conflicts detected at commit
```

---

## Tool Integration: ReAct Controller Support

TreeStore is designed to support all tools from the ReAct controller. Here's how each tool maps to TreeStore operations:

### Tool-to-TreeStore Mapping

| Tool | TreeStore Operation | Store Used | Performance |
|------|-------------------|-----------|-------------|
| **pi_search** | GetNode, GetSubtree + StoreTrajectory | DocumentStore + MetadataStore | <15ms |
| **facts_get** | N/A (external VLM) | - | - |
| **spans_tighten** | GetNode (retrieve text for FTS5) | DocumentStore | <5ms |
| **policy_xref** | GetCrossReferences | MetadataStore | <10ms |
| **temporal_lookup** | GetVersionAsOf | VersionStore | <10ms |
| **code_validator** | N/A (external validation) | - | - |
| **contradiction_detector** | StoreContradiction | MetadataStore | <10ms |
| **pubmed_search** | N/A (external API) | - | - |
| **confidence_score** | GetToolResults (aggregate) | MetadataStore | <15ms |
| **finish** | RecordUsage (track prompt used) | PromptStore | <5ms |

### Example: pi_search Tool Flow

```go
// 1. User calls pi_search(query="What are age requirements?")
query := "What are age requirements?"

// 2. Get tree structure from TreeStore
tree := documentStore.GetSubtree(
    policyID: "LCD-L34220",
    nodeID: rootNodeID,
    maxDepth: 2,
)

// 3. LLM selects relevant nodes
selectedNodeIDs := llmTreeSearch(query, tree)

// 4. Retrieve selected nodes
var results []Node
for _, nodeID := range selectedNodeIDs {
    node := documentStore.GetNode("LCD-L34220", nodeID)
    results = append(results, node)
}

// 5. Store search trajectory in MetadataStore
metadataStore.StoreTrajectory(&SearchTrajectory{
    CaseID:       caseID,
    Query:        query,
    NodesVisited: selectedNodeIDs,
    Thinking:     llmThinking,
    Confidence:   0.92,
    Method:       "llm",
})

// Total time: ~12ms
```

### Example: temporal_lookup Tool Flow

```go
// Tool: temporal_lookup(policy_id="LCD-L34220", as_of_date="2024-01-15")
version := versionStore.GetVersionAsOf(
    policyID: "LCD-L34220",
    asOfDate: parseDate("2024-01-15"),
)

// Returns: 
// - version_id: "2024-01"
// - effective_start: 2024-01-01
// - effective_end: 2024-06-30
// - diffs: [{node_id: "0042", change_type: "modified", ...}]

// Time: ~8ms
```

### Example: policy_xref Tool Flow

```go
// Tool: policy_xref(criterion_id="lumbar-mri-pt")
// Map criterion to node (via metadata or prompt)
nodeID := "0042"

// Get cross-references
refs := metadataStore.GetCrossReferences(nodeID)

// Returns:
// [{
//   from_node_id: "0042",
//   to_node_id: "0087",
//   relation_type: "see_also",
//   reason: "Related eligibility criteria"
// }]

// Retrieve related nodes
var relatedNodes []Node
for _, ref := range refs {
    node := documentStore.GetNode(policyID, ref.ToNodeID)
    relatedNodes = append(relatedNodes, node)
}

// Time: ~12ms
```

### Benefits for ReAct Controller

1. **Fast Tool Execution** - Sub-20ms for most operations
2. **Auditability** - All trajectories and tool results stored
3. **Version Control** - Track policy changes over time
4. **Cross-Reference Navigation** - Explore policy relationships
5. **Prompt Tracking** - Know which prompt version produced which decision

---

## Monitoring & Observability

**Implementation Status:** âŒ NOT IMPLEMENTED (Week 16 in progress)

**Current State:**
- No Prometheus metrics instrumentation
- No structured logging (~51 `fmt.Printf` statements for debugging)
- No monitoring endpoints
- No health checks
- No profiling endpoints
- No request tracing

**Planned Metrics (Week 16):**

**Performance Metrics:**
- `treestore_query_duration_seconds` - Query latency histogram (p50, p95, p99)
- `treestore_transaction_duration_seconds` - Transaction duration
- `treestore_cache_hit_rate` - Cache hit rate percentage
- `treestore_disk_io_operations_total` - Disk I/O operations counter

**System Health Metrics:**
- `treestore_active_transactions` - Active transactions gauge
- `treestore_wal_size_bytes` - WAL size in bytes
- `treestore_index_size_bytes` - Index sizes by type
- `treestore_memory_usage_bytes` - Memory usage
- `treestore_goroutines` - Goroutine count

**Business Metrics:**
- `treestore_documents_total` - Total documents stored
- `treestore_nodes_per_document` - Average nodes per document
- `treestore_query_types_total` - Query types distribution counter
- `treestore_errors_total` - Error rates by operation and type

**Planned Logging (Week 16):**

**Structured logs with:**
- Request ID (for tracing)
- Operation type (GetNode, StoreDocument, etc.)
- Latency (milliseconds)
- Error details (if any)
- Query parameters (sanitized)
- User/policy context

**Log Levels:**
- DEBUG: Detailed B+Tree operations, cache hits/misses
- INFO: Request/response logging, successful operations
- WARN: Slow queries (>100ms), cache evictions
- ERROR: Failed operations, corruption detected

**Current Workaround:**
- Basic `fmt.Printf` debugging statements
- No centralized logging
- No log aggregation
- Acceptable for development, NOT for production

---

## API Layer (gRPC)

**Implementation Status:** âŒ NOT IMPLEMENTED (Week 15 in progress)

**Current State:**
- No `.proto` files in the project
- `cmd/treestore/` directory exists but is empty (no `main.go`)
- `client/python/treestore/` directory exists but is empty
- TreeStore currently only usable as a Go library

**Planned gRPC API:**
```protobuf
service TreeStoreService {
    // Document operations
    rpc StoreDocument(StoreDocumentRequest) returns (StoreDocumentResponse);
    rpc GetDocument(GetDocumentRequest) returns (GetDocumentResponse);
    rpc DeleteDocument(DeleteDocumentRequest) returns (DeleteDocumentResponse);
    
    // Node operations
    rpc GetNode(GetNodeRequest) returns (GetNodeResponse);
    rpc GetChildren(GetChildrenRequest) returns (GetChildrenResponse);
    rpc GetSubtree(GetSubtreeRequest) returns (GetSubtreeResponse);
    rpc GetAncestorPath(GetAncestorPathRequest) returns (GetAncestorPathResponse);
    
    // Search operations
    rpc SearchByKeyword(SearchRequest) returns (SearchResponse);
    rpc GetNodesByPage(GetNodesByPageRequest) returns (GetNodesByPageResponse);
    
    // Version operations (temporal_lookup tool)
    rpc GetVersionAsOf(GetVersionAsOfRequest) returns (PolicyVersion);
    rpc ListVersions(ListVersionsRequest) returns (ListVersionsResponse);
    
    // Metadata operations (tool results, trajectories)
    rpc StoreToolResult(StoreToolResultRequest) returns (StoreToolResultResponse);
    rpc GetToolResults(GetToolResultsRequest) returns (GetToolResultsResponse);
    rpc StoreTrajectory(StoreTrajectoryRequest) returns (StoreTrajectoryResponse);
    rpc GetTrajectories(GetTrajectoriesRequest) returns (GetTrajectoriesResponse);
    rpc StoreCrossReference(StoreCrossReferenceRequest) returns (StoreCrossReferenceResponse);
    rpc GetCrossReferences(GetCrossReferencesRequest) returns (GetCrossReferencesResponse);
    rpc StoreContradiction(StoreContradictionRequest) returns (StoreContradictionResponse);
    
    // Prompt operations
    rpc StorePrompt(StorePromptRequest) returns (StorePromptResponse);
    rpc GetPrompt(GetPromptRequest) returns (GetPromptResponse);
    rpc RecordPromptUsage(RecordPromptUsageRequest) returns (RecordPromptUsageResponse);
    
    // Health & monitoring
    rpc Health(HealthRequest) returns (HealthResponse);
    rpc Stats(StatsRequest) returns (StatsResponse);
}
```

**Python Client (Planned):**
```python
class TreeStoreClient:
    def __init__(self, host='localhost', port=50051, timeout=30):
        # gRPC channel setup
    
    def store_document(self, policy_id: str, tree_json: dict) -> str:
        """Store PageIndex output"""
    
    def get_node(self, policy_id: str, node_id: str) -> dict:
        """Retrieve single node"""
    
    def get_subtree(self, policy_id: str, node_id: str, max_depth: int = None) -> dict:
        """Get hierarchical tree for pi_search tool"""
    
    def get_version_as_of(self, policy_id: str, as_of_date: str) -> dict:
        """Temporal lookup for temporal_lookup tool"""
    
    def store_tool_result(self, case_id: str, tool_name: str, result: dict):
        """Store tool execution result"""
    
    def get_cross_references(self, node_id: str) -> list:
        """Get cross-references for policy_xref tool"""
```

**Blocking Integration:**
- reasoning-service cannot use TreeStore until gRPC API is implemented
- All 10 ReAct tools need Python client to access TreeStore
- Migration from PostgreSQL blocked until Python client is ready

---

## Deployment Architecture

**Implementation Status:** âŒ NOT IMPLEMENTED (Week 16 in progress)

**Planned Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Python Reasoning Service (Existing)            â”‚
â”‚  â”œâ”€ FastAPI endpoints                           â”‚
â”‚  â””â”€ TreeStore Python Client â”€â”€â”                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ gRPC
                                 â”‚ localhost:50051
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TreeStore (Go) - Same Host                     â”‚
â”‚  â”œâ”€ gRPC Server (:50051)       [NOT IMPL]       â”‚
â”‚  â”œâ”€ Data Dir: /var/lib/treestore/               â”‚
â”‚  â”œâ”€ WAL: /var/lib/treestore/wal/  [NOT IMPL]   â”‚
â”‚  â””â”€ Metrics: :9090/metrics     [NOT IMPL]       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”‚ Prometheus scrape
                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Monitoring Stack                  [NOT IMPL]   â”‚
â”‚  â”œâ”€ Prometheus                                  â”‚
â”‚  â”œâ”€ Grafana                                     â”‚
â”‚  â””â”€ Alertmanager                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Current Deployment Model:**
- âŒ No deployment artifacts (Dockerfile, K8s manifests)
- âŒ No monitoring/observability
- âŒ No health checks
- âœ… Core engine works as Go library

**Planned Deployment Model (Week 16):**
- Single-node deployment (start simple)
- Co-located with reasoning-service
- Local disk for storage
- Docker + Kubernetes deployment
- Prometheus + Grafana monitoring
- Future: Replication for HA

---

## Trade-offs & Design Decisions

### 1. B+Tree vs LSM-Tree

**Chose B+Tree because:**
- âœ… Better read performance
- âœ… Simpler implementation
- âœ… Predictable latency
- âœ… Efficient range scans

**Trade-off:**
- âŒ Slower writes than LSM
- âŒ More write amplification

**Justification:** Read-heavy workload (tree traversal queries)

### 2. Single-Node vs Distributed

**Chose Single-Node because:**
- âœ… Simpler implementation
- âœ… No network partitions
- âœ… Easier transactions
- âœ… Sufficient for MVP

**Trade-off:**
- âŒ No horizontal scaling
- âŒ Single point of failure

**Justification:** Start simple, add replication if needed

### 3. MVCC vs Lock-Based

**Chose MVCC because:**
- âœ… Readers never block writers
- âœ… Better concurrency
- âœ… Snapshot isolation

**Trade-off:**
- âŒ More complex implementation
- âŒ Garbage collection needed

**Justification:** Better for production workloads

---

## Future Enhancements

### Phase 2 (Optional)

1. **Replication**
   - Leader-follower setup
   - Async replication
   - Failover support

2. **Compression**
   - Compress leaf node values
   - Reduce disk usage
   - Trade CPU for space

3. **Query Optimization**
   - Query planner
   - Index selection
   - Statistics collection

4. **Hybrid Vector Search** (Advanced)
   - Optional embeddings for semantic reranking
   - Keeps structural retrieval as primary
   - Adds semantic layer on top

---

## References

- Build Your Own Database From Scratch in Go
- Database Internals by Alex Petrov
- PostgreSQL MVCC Documentation
- go-memdb source code
- BadgerDB design documents

---

## Architecture Review Checklist

- [x] Clear separation of concerns
- [x] ACID compliance
- [x] Crash recovery plan
- [x] Concurrency strategy
- [x] Performance targets defined
- [x] Monitoring strategy
- [x] Deployment model
- [x] Trade-offs documented

