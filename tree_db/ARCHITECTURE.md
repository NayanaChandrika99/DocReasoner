# TreeStore Architecture

## System Overview

TreeStore is a specialized hierarchical document database built from scratch in Go. It's designed to store and efficiently query tree-structured documents generated by PageIndex.

---

## Core Design Principles

### 1. **No Vector Embeddings**
TreeStore aligns with PageIndex's philosophy that reasoning-based retrieval is superior to similarity search. We store structural relationships, not semantic embeddings.

### 2. **Hierarchical First**
The database is optimized for tree operations (parent/child, ancestors, subtrees) rather than flat key-value access.

### 3. **ACID Compliance**
Support atomic transactions, durability via WAL, and snapshot isolation for concurrent access.

### 4. **Performance Focus**
Sub-10ms query latency for typical document operations through careful indexing and caching.

---

## High-Level Architecture

```
┌─────────────────────────────────────────────────────────────┐
│                    TreeStore System (Extended)              │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  ┌────────────────────────────────────────────────────┐    │
│  │              gRPC API Layer                        │    │
│  │  - Request validation                              │    │
│  │  - Error handling                                  │    │
│  │  - Metrics collection                              │    │
│  └───────────────────┬────────────────────────────────┘    │
│                      │                                       │
│  ┌───────────────────▼────────────────────────────────┐    │
│  │          Service Layer (Multiple Stores)           │    │
│  │                                                     │    │
│  │  DocumentService - Policy tree nodes & hierarchy   │    │
│  │  VersionService  - Temporal queries & versioning   │    │
│  │  MetadataService - Tool results & trajectories     │    │
│  │  PromptService   - Prompt versioning               │    │
│  └───────────────────┬────────────────────────────────┘    │
│                      │                                       │
│  ┌───────────────────▼────────────────────────────────┐    │
│  │           Index Manager (Multiple B+Trees)         │    │
│  │                                                     │    │
│  │  DocumentStore:                                    │    │
│  │  ├─ Primary Index  (policy_id, node_id)           │    │
│  │  ├─ Parent Index   (policy_id, parent_id)         │    │
│  │  └─ Page Index     (policy_id, page_num)          │    │
│  │                                                     │    │
│  │  VersionStore:                                     │    │
│  │  └─ Temporal Index (policy_id, effective_date)    │    │
│  │                                                     │    │
│  │  MetadataStore:                                    │    │
│  │  ├─ Tool Results   (case_id, tool_name)           │    │
│  │  ├─ Trajectories   (case_id, timestamp)           │    │
│  │  └─ Cross-Refs     (from_node_id, to_node_id)     │    │
│  │                                                     │    │
│  │  PromptStore:                                      │    │
│  │  └─ Prompts        (prompt_id, version)           │    │
│  └───────────────────┬────────────────────────────────┘    │
│                      │                                       │
│  ┌───────────────────▼────────────────────────────────┐    │
│  │          Transaction Manager (MVCC)                │    │
│  │  - Begin/Commit/Rollback                          │    │
│  │  - Snapshot isolation                             │    │
│  │  - Conflict detection                             │    │
│  └───────────────────┬────────────────────────────────┘    │
│                      │                                       │
│  ┌───────────────────▼────────────────────────────────┐    │
│  │             B+Tree Storage Engine                  │    │
│  │  - Insert/Get/Delete/RangeScan                    │    │
│  │  - Node splitting/merging                         │    │
│  │  - Tree rebalancing                               │    │
│  └───────────────────┬────────────────────────────────┘    │
│                      │                                       │
│  ┌───────────────────▼────────────────────────────────┐    │
│  │              Page Manager                          │    │
│  │  - Page allocation/deallocation                   │    │
│  │  - Buffer pool (LRU cache)                        │    │
│  │  - Free list management                           │    │
│  └───────────────────┬────────────────────────────────┘    │
│                      │                                       │
│  ┌───────────────────▼────────────────────────────────┐    │
│  │         Write-Ahead Log (WAL)                      │    │
│  │  - Sequential log writing                         │    │
│  │  - Crash recovery                                 │    │
│  │  - Checkpointing                                  │    │
│  └───────────────────┬────────────────────────────────┘    │
│                      │                                       │
│  ┌───────────────────▼────────────────────────────────┐    │
│  │              Disk I/O Layer                        │    │
│  │  - File operations                                │    │
│  │  - Fsync for durability                           │    │
│  │  - OS page cache interaction                      │    │
│  └────────────────────────────────────────────────────┘    │
└─────────────────────────────────────────────────────────────┘
```

---

## Component Details

### 1. Storage Engine (B+Tree)

**Purpose:** Core data structure for storing and retrieving key-value pairs

**Design Decisions:**
- **B+Tree over LSM-Tree:** Better for read-heavy workloads and range scans
- **Page Size:** 4KB (matches OS page size for efficiency)
- **Fanout:** ~100-200 keys per node (minimizes tree height)
- **Leaf Node Chaining:** Enables efficient range scans

**Key Operations:**
```go
type BTree interface {
    Insert(key, value []byte) error
    Get(key []byte) ([]byte, error)
    Delete(key []byte) error
    RangeScan(start, end []byte) Iterator
}
```

**Data Layout:**
```
Internal Node:
┌────────────────────────────────────────┐
│ Header | N | Key1 | Ptr1 | Key2 | Ptr2 │...
└────────────────────────────────────────┘

Leaf Node:
┌─────────────────────────────────────────┐
│ Header | N | Key1 | Val1 | Key2 | Val2 │... | NextLeafPtr
└─────────────────────────────────────────┘
```

---

### 2. Write-Ahead Log (WAL)

**Purpose:** Ensure durability and enable crash recovery

**Design:**
```
Log Entry Format:
┌──────────────────────────────────────────────┐
│ Timestamp | TxnID | OpType | Key | Value | CRC
└──────────────────────────────────────────────┘

OpType: INSERT, DELETE, CHECKPOINT, COMMIT
```

**Write Process:**
1. Write operation → WAL entry
2. Append to log file
3. Fsync to disk
4. Update in-memory B+Tree
5. Return success

**Recovery Process:**
1. Read all log entries after last checkpoint
2. Replay operations into B+Tree
3. Rebuild indexes
4. Resume normal operation

**Log Rotation:**
- New log file every 100MB
- Keep last 3 log files
- Background checkpoint process

---

### 3. Index Manager

**Purpose:** Maintain multiple B+Trees for different access patterns

**Indexes:**

#### Primary Index
```
Key:   (policy_id, node_id)
Value: {title, parent_id, page_start, page_end, summary, text, ...}
```

#### Parent Index
```
Key:   (policy_id, parent_id, child_node_id)
Value: node_id
Purpose: Fast GetChildren() queries
```

#### Page Index
```
Key:   (policy_id, page_num, node_id)
Value: node_id
Purpose: Find nodes by page number
```

#### Path Index
```
Key:   (policy_id, path_hash)
Value: node_id
Purpose: Fast path-based lookups
```

**Consistency:**
All indexes updated atomically within transaction

---

### 4. Transaction Manager (MVCC)

**Purpose:** Provide snapshot isolation for concurrent transactions

**Design:**
- **Timestamp Ordering:** Each transaction gets monotonic timestamp
- **Version Chains:** Multiple versions of same key
- **Garbage Collection:** Remove old versions when no longer needed

**Transaction Lifecycle:**
```go
txn := db.BeginTransaction()
defer txn.Rollback()  // Cleanup if not committed

// Reads see snapshot at txn start time
value := txn.Get(key)

// Writes are buffered
txn.Put(key, newValue)

// Atomic commit
txn.Commit()
```

**Isolation Levels:**
- Default: Snapshot Isolation (SI)
- Optional: Serializable (detect write-write conflicts)

---

### 5. Service Layer (Extended with Multiple Stores)

TreeStore now consists of **four specialized stores** that share the same underlying B+Tree infrastructure:

#### A. DocumentStore - Policy Tree Nodes

**Purpose:** Store and query hierarchical policy documents from PageIndex

**Data Model:**
```go
type Document struct {
    PolicyID       string
    VersionID      string
    PageIndexDocID string
    RootNodeID     string
    NodeCount      int
    EffectiveDate  *time.Time  // NEW: For temporal queries
    RevisionDate   *time.Time  // NEW
    CreatedAt      time.Time
    Metadata       DocumentMetadata  // NEW
}

type DocumentMetadata struct {
    ProcessedBy    string
    PageCount      int
    ToolsUsed      []string
}

type Node struct {
    NodeID       string
    ParentID     *string
    Title        string
    PageStart    int
    PageEnd      int
    Summary      string
    Text         string
    SectionPath  string
    ChildIDs     []string
    
    // NEW: Cross-references
    SeeAlso      []string  // Related node IDs
    ReferencedBy []string  // Nodes referencing this
    
    // NEW: Metadata
    LastUpdated  time.Time
    Confidence   float64   // From PageIndex processing
}
```

#### B. VersionStore - Temporal Queries

**Purpose:** Support `temporal_lookup` tool - get policy version as of specific date

**Data Model:**
```go
type PolicyVersion struct {
    PolicyID      string
    VersionID     string
    EffectiveDate time.Time
    EndDate       *time.Time  // When this version was superseded
    Changes       []VersionDiff
    CreatedAt     time.Time
}

type VersionDiff struct {
    NodeID    string
    ChangeType string  // "added", "modified", "deleted"
    OldValue  string
    NewValue  string
}
```

**Key Operations:**
```go
// Get version effective on a specific date
func (vs *VersionStore) GetVersionAsOf(
    policyID string,
    asOfDate time.Time,
) (*PolicyVersion, error)

// List all versions for a policy
func (vs *VersionStore) ListVersions(
    policyID string,
) ([]*PolicyVersion, error)
```

#### C. MetadataStore - Tool Results & Trajectories

**Purpose:** Store results from ReAct tools (pi_search, facts_get, etc.)

**Data Model:**
```go
// Tool result storage
type ToolResult struct {
    CaseID      string
    CriterionID string
    ToolName    string  // "pi_search", "facts_get", etc.
    Input       map[string]interface{}
    Output      map[string]interface{}
    Timestamp   time.Time
    Latency     time.Duration
    Success     bool
}

// Search trajectory storage (from pi_search)
type SearchTrajectory struct {
    CaseID       string
    Query        string
    NodesVisited []string
    Thinking     string
    Confidence   float64
    Method       string  // "llm", "hybrid", "mcts"
    Timestamp    time.Time
}

// Cross-reference storage (for policy_xref tool)
type CrossReference struct {
    FromNodeID   string
    ToNodeID     string
    RelationType string  // "see_also", "prerequisite", "related"
    Reason       string
    Confidence   float64
}

// Contradiction storage (from contradiction_detector tool)
type Contradiction struct {
    CaseID       string
    CriterionID  string
    Evidence     []EvidencePiece
    Conflicts    []Conflict
    Resolution   string
    Timestamp    time.Time
}

type EvidencePiece struct {
    NodeID   string
    Snippet  string
    Stance   string  // "support", "oppose", "neutral"
}
```

**Key Operations:**
```go
// Store tool result
func (ms *MetadataStore) StoreToolResult(
    result *ToolResult,
) error

// Store search trajectory
func (ms *MetadataStore) StoreTrajectory(
    trajectory *SearchTrajectory,
) error

// Get cross-references for policy_xref tool
func (ms *MetadataStore) GetCrossReferences(
    nodeID string,
) ([]*CrossReference, error)

// Store contradiction for analysis
func (ms *MetadataStore) StoreContradiction(
    contradiction *Contradiction,
) error
```

#### D. PromptStore - Versioned Prompts

**Purpose:** Track which system prompts were used for decisions

**Data Model:**
```go
type Prompt struct {
    PromptID    string
    Version     string
    Content     string
    ToolSchemas []ToolSchema
    CreatedAt   time.Time
    DeployedAt  *time.Time
    RetiredAt   *time.Time
}

type ToolSchema struct {
    Name        string
    Description string
    Parameters  map[string]interface{}
}

type PromptUsage struct {
    CaseID      string
    PromptID    string
    Version     string
    Timestamp   time.Time
}
```

**Key Operations:**
```go
// Store new prompt version
func (ps *PromptStore) StorePrompt(
    prompt *Prompt,
) error

// Get prompt by version
func (ps *PromptStore) GetPrompt(
    promptID string,
    version string,
) (*Prompt, error)

// Track which prompt was used
func (ps *PromptStore) RecordUsage(
    usage *PromptUsage,
) error
```

**Key Operations:**

#### StoreDocument
```go
func (ds *DocumentService) StoreDocument(
    policyID string,
    tree map[string]interface{},
) error {
    txn := ds.db.BeginTransaction()
    defer txn.Rollback()
    
    // Parse tree structure
    nodes := flattenTree(tree)
    
    // Store document metadata
    doc := Document{...}
    txn.Put(docKey, serialize(doc))
    
    // Batch insert all nodes
    for _, node := range nodes {
        // Primary index
        txn.Put(primaryKey(node), serialize(node))
        
        // Secondary indexes
        txn.Put(parentKey(node), node.NodeID)
        txn.Put(pageKey(node), node.NodeID)
    }
    
    return txn.Commit()
}
```

#### GetSubtree
```go
func (ds *DocumentService) GetSubtree(
    policyID string,
    nodeID string,
    maxDepth int,
) (*Node, error) {
    // BFS traversal with depth limit
    root := ds.GetNode(policyID, nodeID)
    queue := [](*Node, int){{root, 0}}
    
    for len(queue) > 0 {
        node, depth := queue[0]
        queue = queue[1:]
        
        if depth < maxDepth {
            children := ds.GetChildren(policyID, node.NodeID)
            node.Children = children
            
            for _, child := range children {
                queue = append(queue, (child, depth+1))
            }
        }
    }
    
    return root, nil
}
```

---

### 6. Full-Text Search

**Purpose:** Keyword search over titles and summaries (NOT semantic)

**Design:**
- **Inverted Index:** word → list of (document, node_id, positions)
- **BM25 Ranking:** Rank results by keyword relevance
- **Stop Words:** Filter common words

**Index Structure:**
```
Word: "eligibility"
Postings: [
    (policy_123, node_0042, [5, 23, 47]),
    (policy_123, node_0043, [12]),
    (policy_456, node_0015, [8, 91])
]
```

**Query Processing:**
1. Tokenize query
2. Lookup each term in inverted index
3. Intersect/union posting lists
4. Score with BM25
5. Return top-K results

---

## Data Flow Examples

### Example 1: Storing PageIndex Output

```
1. Python Client
   ↓
   grpc.StoreDocument(policy_id="POL123", tree_json={...})
   
2. gRPC Server
   ↓
   DocumentService.StoreDocument()
   
3. Document Service
   ↓
   - Flatten tree into nodes
   - Begin transaction
   - For each node:
     * Insert into primary index
     * Update parent index
     * Update page index
     * Update full-text index
   - Commit transaction
   
4. Transaction Manager
   ↓
   - Assign transaction ID
   - Write to WAL
   - Update B+Trees
   - Fsync
   - Return success
```

### Example 2: Tree Traversal Query

```
1. Python Client
   ↓
   grpc.GetSubtree(policy_id="POL123", node_id="0042", max_depth=2)
   
2. gRPC Server
   ↓
   DocumentService.GetSubtree()
   
3. Document Service
   ↓
   - Get root node from primary index
   - BFS traversal:
     * For each node at depth < max_depth:
       - Query parent index for children
       - Fetch child nodes from primary index
   - Assemble tree structure
   - Return result
   
4. B+Tree Storage
   ↓
   - Lookup in primary index: O(log N)
   - Range scan in parent index: O(log N + M) where M = num children
   - Total: O(nodes_in_subtree * log N)
```

---

## Performance Characteristics

### Time Complexity

| Operation | Complexity | Notes |
|-----------|-----------|-------|
| **DocumentStore** | | |
| Get Node | O(log N) | Single B+Tree lookup |
| Get Children | O(log N + M) | Range scan, M = num children |
| Get Subtree | O(K log N) | K = nodes in subtree |
| Insert Node | O(log N * I) | I = num indexes |
| Range Scan | O(log N + M) | M = num results |
| Keyword Search | O(T + R log R) | T = term lookups, R = results |
| **VersionStore** | | |
| Get Version As Of | O(log N) | Range scan on temporal index |
| List Versions | O(log N + V) | V = num versions |
| **MetadataStore** | | |
| Store Tool Result | O(log N) | Single insert |
| Store Trajectory | O(log N) | Single insert |
| Get Cross-Refs | O(log N + R) | R = num references |
| **PromptStore** | | |
| Store Prompt | O(log N) | Single insert |
| Get Prompt | O(log N) | Single lookup |
| **Overall** | | |
| End-to-End Tool Call | O(log N) | Typically <20ms |

### Space Complexity

| Component | Size | Notes |
|-----------|------|-------|
| **DocumentStore** | | |
| B+Tree Node | 4KB | 1 page |
| Policy Node | ~1KB | With indexes |
| Secondary Indexes | ~100 bytes/node | Per index |
| **VersionStore** | | |
| Policy Version | ~500 bytes | Metadata only |
| Version Diffs | ~200 bytes/diff | Small changes |
| **MetadataStore** | | |
| Tool Result | ~500 bytes | Average |
| Search Trajectory | ~1KB | With thinking |
| Cross-Reference | ~100 bytes | Small |
| Contradiction | ~2KB | With evidence |
| **PromptStore** | | |
| Prompt | ~5KB | With schemas |
| Prompt Usage | ~100 bytes | Reference only |
| **WAL** | | |
| WAL Entry | ~500 bytes | Per operation |

**Storage Estimates (Year 1):**
- 50 policies × 200 nodes = 10K nodes × 1.5KB = **15MB** (DocumentStore)
- 1000 cases/day × 10 tools/case × 0.5KB × 365 days = **1.8GB** (MetadataStore)
- 10 prompt versions × 5KB = **50KB** (PromptStore)
- 50 policies × 5 versions × 1KB = **250KB** (VersionStore)

**Total Year 1:** ~2GB (easily cached in memory)

---

## Concurrency Model

### Read-Write Lock Strategy

```
Multiple readers, single writer:
- Readers acquire read lock (shared)
- Writer acquires write lock (exclusive)
- MVCC allows readers to see consistent snapshot
```

### Transaction Isolation

```
Snapshot Isolation (SI):
- Each transaction sees snapshot at start time
- Reads never block writes
- Writes never block reads
- Write-write conflicts detected at commit
```

---

## Tool Integration: ReAct Controller Support

TreeStore is designed to support all tools from the ReAct controller. Here's how each tool maps to TreeStore operations:

### Tool-to-TreeStore Mapping

| Tool | TreeStore Operation | Store Used | Performance |
|------|-------------------|-----------|-------------|
| **pi_search** | GetNode, GetSubtree + StoreTrajectory | DocumentStore + MetadataStore | <15ms |
| **facts_get** | N/A (external VLM) | - | - |
| **spans_tighten** | GetNode (retrieve text for FTS5) | DocumentStore | <5ms |
| **policy_xref** | GetCrossReferences | MetadataStore | <10ms |
| **temporal_lookup** | GetVersionAsOf | VersionStore | <10ms |
| **code_validator** | N/A (external validation) | - | - |
| **contradiction_detector** | StoreContradiction | MetadataStore | <10ms |
| **pubmed_search** | N/A (external API) | - | - |
| **confidence_score** | GetToolResults (aggregate) | MetadataStore | <15ms |
| **finish** | RecordUsage (track prompt used) | PromptStore | <5ms |

### Example: pi_search Tool Flow

```go
// 1. User calls pi_search(query="What are age requirements?")
query := "What are age requirements?"

// 2. Get tree structure from TreeStore
tree := documentStore.GetSubtree(
    policyID: "LCD-L34220",
    nodeID: rootNodeID,
    maxDepth: 2,
)

// 3. LLM selects relevant nodes
selectedNodeIDs := llmTreeSearch(query, tree)

// 4. Retrieve selected nodes
var results []Node
for _, nodeID := range selectedNodeIDs {
    node := documentStore.GetNode("LCD-L34220", nodeID)
    results = append(results, node)
}

// 5. Store search trajectory in MetadataStore
metadataStore.StoreTrajectory(&SearchTrajectory{
    CaseID:       caseID,
    Query:        query,
    NodesVisited: selectedNodeIDs,
    Thinking:     llmThinking,
    Confidence:   0.92,
    Method:       "llm",
})

// Total time: ~12ms
```

### Example: temporal_lookup Tool Flow

```go
// Tool: temporal_lookup(policy_id="LCD-L34220", as_of_date="2024-01-15")
version := versionStore.GetVersionAsOf(
    policyID: "LCD-L34220",
    asOfDate: parseDate("2024-01-15"),
)

// Returns: 
// - version_id: "2024-01"
// - effective_start: 2024-01-01
// - effective_end: 2024-06-30
// - diffs: [{node_id: "0042", change_type: "modified", ...}]

// Time: ~8ms
```

### Example: policy_xref Tool Flow

```go
// Tool: policy_xref(criterion_id="lumbar-mri-pt")
// Map criterion to node (via metadata or prompt)
nodeID := "0042"

// Get cross-references
refs := metadataStore.GetCrossReferences(nodeID)

// Returns:
// [{
//   from_node_id: "0042",
//   to_node_id: "0087",
//   relation_type: "see_also",
//   reason: "Related eligibility criteria"
// }]

// Retrieve related nodes
var relatedNodes []Node
for _, ref := range refs {
    node := documentStore.GetNode(policyID, ref.ToNodeID)
    relatedNodes = append(relatedNodes, node)
}

// Time: ~12ms
```

### Benefits for ReAct Controller

1. **Fast Tool Execution** - Sub-20ms for most operations
2. **Auditability** - All trajectories and tool results stored
3. **Version Control** - Track policy changes over time
4. **Cross-Reference Navigation** - Explore policy relationships
5. **Prompt Tracking** - Know which prompt version produced which decision

---

## Monitoring & Observability

### Metrics Collected

**Performance:**
- Query latency (p50, p95, p99)
- Transaction duration
- Cache hit rate
- Disk I/O operations

**System Health:**
- Active transactions
- WAL size
- Index sizes
- Memory usage
- Goroutine count

**Business:**
- Documents stored
- Nodes per document
- Query types distribution
- Error rates by operation

### Logging

**Structured logs with:**
- Request ID
- Operation type
- Latency
- Error details
- Query parameters (sanitized)

---

## Deployment Architecture

```
┌─────────────────────────────────────────────────┐
│  Python Reasoning Service (Existing)            │
│  ├─ FastAPI endpoints                           │
│  └─ TreeStore Python Client ──┐                 │
└────────────────────────────────│────────────────┘
                                 │ gRPC
                                 │ localhost:50051
┌────────────────────────────────▼────────────────┐
│  TreeStore (Go) - Same Host                     │
│  ├─ gRPC Server (:50051)                        │
│  ├─ Data Dir: /var/lib/treestore/               │
│  ├─ WAL: /var/lib/treestore/wal/                │
│  └─ Metrics: :9090/metrics                      │
└─────────────────────────────────────────────────┘
                    │
                    │ Prometheus scrape
                    ▼
┌─────────────────────────────────────────────────┐
│  Monitoring Stack                               │
│  ├─ Prometheus                                  │
│  ├─ Grafana                                     │
│  └─ Alertmanager                                │
└─────────────────────────────────────────────────┘
```

**Deployment Model:**
- Single-node deployment (start simple)
- Co-located with reasoning-service
- Local disk for storage
- Future: Replication for HA

---

## Trade-offs & Design Decisions

### 1. B+Tree vs LSM-Tree

**Chose B+Tree because:**
- ✅ Better read performance
- ✅ Simpler implementation
- ✅ Predictable latency
- ✅ Efficient range scans

**Trade-off:**
- ❌ Slower writes than LSM
- ❌ More write amplification

**Justification:** Read-heavy workload (tree traversal queries)

### 2. Single-Node vs Distributed

**Chose Single-Node because:**
- ✅ Simpler implementation
- ✅ No network partitions
- ✅ Easier transactions
- ✅ Sufficient for MVP

**Trade-off:**
- ❌ No horizontal scaling
- ❌ Single point of failure

**Justification:** Start simple, add replication if needed

### 3. MVCC vs Lock-Based

**Chose MVCC because:**
- ✅ Readers never block writers
- ✅ Better concurrency
- ✅ Snapshot isolation

**Trade-off:**
- ❌ More complex implementation
- ❌ Garbage collection needed

**Justification:** Better for production workloads

---

## Future Enhancements

### Phase 2 (Optional)

1. **Replication**
   - Leader-follower setup
   - Async replication
   - Failover support

2. **Compression**
   - Compress leaf node values
   - Reduce disk usage
   - Trade CPU for space

3. **Query Optimization**
   - Query planner
   - Index selection
   - Statistics collection

4. **Hybrid Vector Search** (Advanced)
   - Optional embeddings for semantic reranking
   - Keeps structural retrieval as primary
   - Adds semantic layer on top

---

## References

- Build Your Own Database From Scratch in Go
- Database Internals by Alex Petrov
- PostgreSQL MVCC Documentation
- go-memdb source code
- BadgerDB design documents

---

## Architecture Review Checklist

- [x] Clear separation of concerns
- [x] ACID compliance
- [x] Crash recovery plan
- [x] Concurrency strategy
- [x] Performance targets defined
- [x] Monitoring strategy
- [x] Deployment model
- [x] Trade-offs documented

